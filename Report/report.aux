\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{9781107077232}
\providecommand \oddpage@label [2]{}
\select@language{british}
\@writefile{toc}{\select@language{british}}
\@writefile{lof}{\select@language{british}}
\@writefile{lot}{\select@language{british}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}A brief overview of clustering}{1}{subsection.1.1}}
\citation{zaki2014dataminingbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Clustering Validation}{2}{subsection.1.2}}
\citation{scikit-learn}
\citation{doi:10.1109/MCSE.2011.37}
\citation{Hunter_2007}
\citation{hastie01statisticallearning}
\citation{MR2372475}
\citation{zaki2014dataminingbook}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}The USGS Catalog}{5}{subsection.1.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Clustering Algorithms}{5}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}K-Means Algorithm}{5}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Algorithm for K-means Clustering}{7}{subsubsection.2.1.1}}
\citation{Ester96adensity-based}
\citation{zaki2014dataminingbook}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Choosing the number of clusters}{8}{subsubsection.2.1.2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Values of the Precision, Recall, F1-Score, Rand index, adjusted Rand index and Silhouette score at the $k$ maximising the index considered in the row.}}{8}{table.1}}
\newlabel{table:kmeans}{{1}{8}{Values of the Precision, Recall, F1-Score, Rand index, adjusted Rand index and Silhouette score at the $k$ maximising the index considered in the row}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}DBSCAN}{8}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the K-Means algorithms at different values of $k$.}}{9}{figure.1}}
\newlabel{fig:kmeans}{{1}{9}{Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the K-Means algorithms at different values of $k$}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Representation of the clustering obtained applying the K-Means algorithm with $k= 25$.}}{10}{figure.2}}
\newlabel{fig:kmeans_world}{{2}{10}{Representation of the clustering obtained applying the K-Means algorithm with $k= 25$}{figure.2}{}}
\citation{Ester96adensity-based}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the DBSCAN algorithm for different values of $\varepsilon $.}}{11}{figure.3}}
\newlabel{fig:dbscan}{{3}{11}{Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the DBSCAN algorithm for different values of $\varepsilon $}{figure.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Choosing the parameters for the DBSCAN}{11}{subsubsection.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Number of clusters obtained via the DBSCAN algorithm for different values of $\varepsilon $.}}{12}{figure.4}}
\newlabel{fig:dbscan_clusters}{{4}{12}{Number of clusters obtained via the DBSCAN algorithm for different values of $\varepsilon $}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces $4$-th distance of the points in the dataset sorted in decreasing order. The $4$-th distance is defined as the distance between a given point and its fourth closest neighbour.}}{12}{figure.5}}
\newlabel{fig:dbscan_distance}{{5}{12}{$4$-th distance of the points in the dataset sorted in decreasing order. The $4$-th distance is defined as the distance between a given point and its fourth closest neighbour}{figure.5}{}}
\citation{Ester96adensity-based}
\citation{Ester96adensity-based}
\citation{Bishop:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Gaussian Mixture}{13}{subsection.2.3}}
\newlabel{eqn::gauss_mix}{{1}{13}{Gaussian Mixture}{equation.2.1}{}}
\newlabel{eqn::posterior}{{2}{13}{Gaussian Mixture}{equation.2.2}{}}
\newlabel{eqn::log_lik}{{3}{13}{Gaussian Mixture}{equation.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}EM for Gaussian mixtures}{14}{subsubsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the Gaussian Mixture Model algorithms for different values $n$ of its components.}}{15}{figure.6}}
\newlabel{fig:gmm}{{6}{15}{Precision, Recall, F1-Score, Rand Index, Adjusted Rand Index and Silhouette Score for the Gaussian Mixture Model algorithms for different values $n$ of its components}{figure.6}{}}
\citation{Bishop:2006}
\citation{Schwarz_1978}
\bibstyle{alpha}
\bibdata{bibliography_biblatex}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Representation of the clustering obtained applying the Gaussiam Model Mixture algorithm with $n= 198$.}}{16}{figure.7}}
\newlabel{fig:gmm_world}{{7}{16}{Representation of the clustering obtained applying the Gaussiam Model Mixture algorithm with $n= 198$}{figure.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Choosing the number of components}{16}{subsubsection.2.3.2}}
\bibcite{Bishop:2006}{Bis06}
\bibcite{Ester96adensity-based}{EKSX96}
\bibcite{hastie01statisticallearning}{HTF01}
\bibcite{Hunter_2007}{Hun07}
\bibcite{MR2372475}{JW07}
\bibcite{9781107077232}{LRU14}
\bibcite{scikit-learn}{PVG{$^{+}$}11}
\bibcite{Schwarz_1978}{Sch78}
\bibcite{doi:10.1109/MCSE.2011.37}{vdWCV11}
\bibcite{zaki2014dataminingbook}{ZWM14}
